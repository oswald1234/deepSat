{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240046b6",
   "metadata": {},
   "source": [
    "### Preprocess Raw-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f723f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for sentinel products in:\n",
      " /media/oskar/ESSD/deepSat/raw-data/sentinel-2/Tidsperiod-1/ \n",
      "\n",
      "---- Found sentinel products: ----\n",
      "Found: T33UUB 2018-07-26 10:20:19 S2B_MSIL1C_20180726T102019_N0206_R065_T33UUB_20180726T142914.SAFE\n",
      "Found: T33VUC 2018-07-04 10:30:21 S2A_MSIL1C_20180704T103021_N0206_R108_T33VUC_20180704T174024.SAFE\n",
      "Found: T33VUD 2018-06-29 10:30:19 S2B_MSIL1C_20180629T103019_N0206_R108_T33VUD_20180629T123841.SAFE\n",
      "Found: T33VUE 2018-07-04 10:30:21 S2A_MSIL1C_20180704T103021_N0206_R108_T33VUE_20180704T174024.SAFE\n",
      "Found: T33VVD 2018-07-26 10:20:19 S2B_MSIL1C_20180726T102019_N0206_R065_T33VVD_20180726T142914.SAFE\n",
      "Found: T33VVE 2018-06-01 10:20:21 S2A_MSIL1C_20180601T102021_N0206_R065_T33VVE_20180601T123308.SAFE\n",
      "Found: T33VVF 2018-07-04 10:30:21 S2A_MSIL1C_20180704T103021_N0206_R108_T33VVF_20180704T174024.SAFE\n",
      "Found: T33VWE 2018-06-01 10:20:21 S2A_MSIL1C_20180601T102021_N0206_R065_T33VWE_20180601T123308.SAFE\n",
      "Found: T33VWF 2018-06-01 10:20:21 S2A_MSIL1C_20180601T102021_N0206_R065_T33VWF_20180601T123308.SAFE\n",
      "Found: T33VWG 2018-06-01 10:20:21 S2A_MSIL1C_20180601T102021_N0206_R065_T33VWG_20180601T123308.SAFE\n",
      "Found: T33VXF 2018-06-28 10:10:31 S2A_MSIL1C_20180628T101031_N0206_R022_T33VXF_20180628T110856.SAFE\n",
      "Found: T33VXG 2018-06-03 10:10:19 S2B_MSIL1C_20180603T101019_N0206_R022_T33VXG_20180603T121720.SAFE\n",
      "Found: T34VCL 2018-06-28 10:10:31 S2A_MSIL1C_20180628T101031_N0206_R022_T34VCL_20180628T110856.SAFE\n",
      "Found: T34VCM 2018-06-03 10:10:19 S2B_MSIL1C_20180603T101019_N0206_R022_T34VCM_20180603T121720.SAFE\n",
      "Found: T34VDR 2018-07-16 10:20:19 S2B_MSIL1C_20180716T102019_N0206_R065_T34VDR_20180716T140253.SAFE\n",
      "Found: T34WDS 2018-07-16 10:20:19 S2B_MSIL1C_20180716T102019_N0206_R065_T34WDS_20180716T140253.SAFE\n",
      "\n",
      "---- Found LULC data: ----\n",
      "Found: SE002L1_GOTEBORG_UA2018_v013.gpkg\n",
      "Found: SE007L1_LINKOPING_UA2018_v013.gpkg\n",
      "Found: SE001L1_STOCKHOLM_UA2018_v013.gpkg\n",
      "Found: SE003L1_MALMO_UA2018_v013.gpkg\n",
      "Found: SE004L1_JONKOPING_UA2018_v013.gpkg\n",
      "Found: SE005L1_UMEA_UA2018_v013.gpkg\n",
      "Found: SE006L1_UPPSALA_UA2018_v013.gpkg\n",
      "Found: SE008L1_OREBRO_UA2018_v013.gpkg\n",
      "Found: SE501L1_VASTERAS_UA2018_v013.gpkg\n",
      "Found: SE503L1_HELSINGBORG_UA2018_v013.gpkg\n",
      "Found: SE505L1_BORAS_UA2018_v013.gpkg\n",
      "Found: SE502L1_NORRKOPING_UA2018_v013.gpkg\n",
      "\n",
      " Save processed data to: \n",
      " /media/oskar/ESSD/deepSat/processed-data/TCI_256/Tidsperiod-1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "# path to 'deepSat' containing: \n",
    "# \"raw-data/AOI/tile_selection.gpkg\", \n",
    "# 'raw-data/AOI/patch_size_features.gpkg', \n",
    "# 'raw-data/LULC-Sweden/*/Data/*.gpkg'\n",
    "# 'raw-data/sentinel-2/Tidsperiod-x/'\n",
    "\n",
    "root_path = '/media/oskar/ESSD/deepSat/'\n",
    "timeperiod = 1 # timeperiod (tp) 1 eller 2\n",
    "\n",
    "patch_size =256  #choose between ['64','128','256']\n",
    "source = 'TCI' # for savedir... e.g. TCI => TCI_256 if patch_size=256\n",
    "data_source = source + '_{}'.format(patch_size)\n",
    "tp = 'Tidsperiod-{}'.format(timeperiod)\n",
    "sdir = os.path.join(root_path,'processed-data/{source}/{tp}'.format(source=data_source,tp=tp))\n",
    "\n",
    "import glob\n",
    "import h5netcdf\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray as rio\n",
    "from geopandas import read_file\n",
    "from tqdm.notebook import tqdm\n",
    "from preprocess.uaUtils import open_fua\n",
    "from preprocess.s2Utils import search_product,open_tile,clip_tile,open_clip_tile, get_tile_info, get_prod_info\n",
    "from preprocess.utils import rasterize,get_obj_within,str_to_oao, save_cube,class_dict,org_files\n",
    "\n",
    "xr.set_options(keep_attrs=True)\n",
    "\n",
    "\n",
    "# path to Urban Atlas (UA) data\n",
    "ua_paths = glob.glob(os.path.join(root_path,'raw-data/LULC-Sweden/*/Data/*.gpkg'))\n",
    "\n",
    "# path to s2 products\n",
    "s2_path = os.path.join(root_path,'raw-data/sentinel-2/{}/'.format(tp))\n",
    "print('Looking for sentinel products in:\\n',s2_path,'\\n')\n",
    "ua_crs = read_file(ua_paths[0]).crs\n",
    "\n",
    "# path to s2 tiles to use \n",
    "s2tiles = read_file(os.path.join(root_path,'raw-data/AOI/tile_selection.gpkg')).to_crs(ua_crs)\n",
    "\n",
    "# path to scb patches of size*size\n",
    "scb_grid = read_file(os.path.join(root_path,'raw-data/AOI/patch_size_features.gpkg'),layer = \"patch_{}\".format(patch_size)).to_crs(ua_crs)\n",
    "\n",
    "\n",
    "# check that desired s2tiles existst in s2_path\n",
    "print('---- Found sentinel products: ----')\n",
    "for tile in s2tiles.itertuples():\n",
    "    prod,date= search_product(tile.Name,s2_path)\n",
    "    \n",
    "    if prod:\n",
    "        for i, prod in enumerate(prod):\n",
    "            fn=os.path.basename(prod)\n",
    "            print('Found:',get_prod_info(fn)['Tile'],pd.to_datetime(date[i]),fn)\n",
    "    else:\n",
    "        print('No found sentinel products for tile:',tile.Name)\n",
    "          \n",
    "# list found FUAS\n",
    "print('\\n---- Found LULC data: ----')\n",
    "if ua_paths:\n",
    "    for ua_path in ua_paths:\n",
    "        print('Found:',os.path.basename(ua_path))\n",
    "else:\n",
    "    print('No LULC data found')\n",
    "    \n",
    "\n",
    "print('\\n Save processed data to: \\n',  sdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a891104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65466f9464ce4af4b781212fd4b73aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Total progress:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f928ad3d1be4106b6c64086fd315a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Intersecting tiles:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01316c41a20548ac9821b996e8327fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FUA: GOTEBORG, Tile: 33VUD:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# open UA data\n",
    "bad_patch=[]\n",
    "for path in tqdm(ua_paths, desc='Total progress'):\n",
    "    \n",
    "    fua_labls,fua_bound = open_fua(path)             # open fua layers\n",
    "    tiles_inters = s2tiles.sjoin(fua_bound, predicate='intersects')  #get intersecting tiles for fua\n",
    "    fua_name = str_to_oao(fua_bound.fua_name[0])\n",
    "    \n",
    "    for tile in tqdm(tiles_inters.itertuples(),desc='Intersecting tiles',total=len(tiles_inters)): # for every intersecting tile\n",
    "        \n",
    "        # select patches within curr tile\n",
    "        curr_tile = s2tiles[s2tiles.Name.isin([tile.Name])]                                               \n",
    "        patches_within = get_obj_within(get_obj_within(scb_grid,curr_tile),fua_bound) #select patches(grid) within curr_tile and within fua\n",
    "        #savedir\n",
    "        savedir = os.path.join(sdir,'{}/{}/'.format(fua_name,tile.Name))\n",
    "        #print(savedir)\n",
    "        #open curr tile \n",
    "        s2_tile = open_tile(tile.Name,s2_path)\n",
    "        \n",
    "        for patch in tqdm(patches_within.itertuples(),total=len(patches_within), desc='FUA: {}, Tile: {}'.format(fua_name,tile.Name)):\n",
    "            \n",
    "            # get current patch and clip labels to patch extent\n",
    "            curr_patch = scb_grid[(scb_grid.id.isin([patch.id]))]\n",
    "            # clip tile and labels to patch extent\n",
    "            s2_patch = clip_tile(s2_tile,curr_patch)\n",
    "            patch_labls = fua_labls.clip(curr_patch)\n",
    "            #rasterize patch labels \n",
    "            try:\n",
    "                cube = rasterize(patch_labls)\n",
    "            except:\n",
    "                bad_patch.append(patch.id)\n",
    "            else:    \n",
    "                #merge s2_patch and patch labels\n",
    "                cube = cube.merge(s2_patch.rio.reproject_match(cube)) #append to cube\n",
    "                # reduce coordinate dimensions by one\n",
    "                if cube.dims['x'] > patch_size:\n",
    "                   cube=cube.isel(x=slice(None, -1), y=slice(None, -1))           \n",
    "            \n",
    "                #set attributes to cube before saving\n",
    "                cube.attrs[\"patch_id\"] = patch.id\n",
    "                cube.attrs['FUA'] = fua_name\n",
    "                for key,value in get_tile_info(tile.Name,s2_path).items():\n",
    "                    cube.attrs[key] = value\n",
    "\n",
    "\n",
    "                cube.train_id.attrs['_fillValue']=255\n",
    "                cube.class_code.attrs['_fillValue']=255\n",
    "                save_cube(cube,savedir)\n",
    "           \n",
    "\n",
    "            break\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29143a4",
   "metadata": {},
   "source": [
    "### split train/test/val\n",
    "\n",
    "1. split dataset (if satisfied, execute step 2)\n",
    "2. reorganize files after split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4009c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1 1.0 test: 0 0.0 val: 0 0.0\n"
     ]
    }
   ],
   "source": [
    "#1 split dataset\n",
    "train = 0.8\n",
    "test = 0.5 #of remaining -train\n",
    "\n",
    "df = np.asarray(glob.glob(os.path.join(sdir,'*/*/*.nc')))\n",
    "\n",
    "msk = np.random.rand(len(df)) <train\n",
    "len(msk[msk==True])/len(msk)\n",
    "\n",
    "train = df[msk]\n",
    "testval = df[~msk]\n",
    "msk = np.random.rand(len(testval))<test\n",
    "test=testval[msk]\n",
    "val = testval[~msk]\n",
    "print('train:', len(train) ,round(len(train)/len(df),2),'test:',len(test),round(len(test)/len(df),2),'val:',len(val),round(len(val)/len(df),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d28b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/oskar/ESSD/deepSat/processed-data/TCI_256_split/Tidsperiod-1/train\n"
     ]
    }
   ],
   "source": [
    "if train.size>0: \n",
    "    org_files(train,mode='train')\n",
    "if test.size>0:\n",
    "    org_files(test,mode='test')\n",
    "if val.size>0:\n",
    "    org_files(val,mode='val')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a7be5",
   "metadata": {},
   "source": [
    "#### Compact Naming Convention\n",
    "\n",
    "The compact naming convention is arranged as follows:\n",
    "\n",
    "MMM_MSIXXX_YYYYMMDDHHMMSS_Nxxyy_ROOO_Txxxxx_<Product Discriminator>.SAFE\n",
    "\n",
    "The products contain two dates.\n",
    "\n",
    "The first date (YYYYMMDDHHMMSS) is the datatake sensing time.\n",
    "The second date is the \"Product Discriminator\" field, which is 15 characters in length, and is used to distinguish between different end user products from the same datatake. Depending on the instance, the time in this field can be earlier or slightly later than the datatake sensing time.\n",
    "\n",
    "The other components of the filename are:\n",
    "\n",
    "* MMM: is the mission ID(S2A/S2B)\n",
    "* MSIXXX: MSIL1C denotes the Level-1C product level/ MSIL2A denotes the Level-2A product level\n",
    "* YYYYMMDDHHMMSS: the datatake sensing start time\n",
    "* Nxxyy: the PDGS Processing Baseline number (e.g. N0204)\n",
    "* ROOO: Relative Orbit number (R001 - R143)\n",
    "* Txxxxx: Tile Number field\n",
    "\n",
    "SAFE: Product Format (Standard Archive Format for Europe)\n",
    "\n",
    "Source https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/naming-convention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "denv",
   "language": "python",
   "name": "denv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
