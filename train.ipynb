{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876a90d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# only for testing different stuff \n",
    "# use main.py for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947076a9-f676-42ad-b111-6283eb3398c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample image\n",
    "import torch\n",
    "\n",
    "from dataset.utils import pNormalize\n",
    "from dataset.datasets import sentinel\n",
    "from model.models import UNET\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "q_hi = torch.tensor([2102.0, 1716.0, 1398.0, 4732.0, 2434.42919921875, 3701.759765625, 4519.2177734375, 4857.7734375, 3799.80322265625, 3008.8935546875])\n",
    "q_lo = torch.tensor([102.0, 159.0, 107.0, 77.0, 106.98081970214844, 79.00384521484375, 86.18966674804688, 70.40167236328125, 50.571197509765625, 36.95356750488281])\n",
    "        \n",
    "norm = pNormalize(\n",
    "                maxPer=q_hi,\n",
    "                minPer=q_lo\n",
    ")\n",
    "\n",
    "\n",
    "# Create experimental dataset and loader, rgb=True for 3 channels (default = False)\n",
    "test_set = sentinel(root_dir='processed-data/dsen_2_256_new_split', img_transform=norm)\n",
    "test_loader = DataLoader(test_set, batch_size=10, num_workers=0)\n",
    "\n",
    "print(len(test_set))\n",
    "\n",
    "# access one image from dataset\n",
    "img, label = test_set[0]\n",
    "#print('image shape:', img.shape)\n",
    "\n",
    "\n",
    "# or  batch from DataLoader\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define model\n",
    "model = UNET(in_channels=images.shape[1])\n",
    "model.load_state_dict(torch.load('to/model_epoch_95.pt',map_location=torch.device('cpu')))\n",
    "# disable gradients etc. model.train() for training https://medium.com/jun94-devpblog/pytorch-6-model-train-vs-model-eval-no-grad-hyperparameter-tuning-3812c216a3bd\n",
    "model.eval()\n",
    "\n",
    "output = model(images)\n",
    "\n",
    "#pred = torch.argmax(output, dim=1)\n",
    "     # prediction\n",
    "pred= torch.nn.functional.softmax(output,dim=1)\n",
    "pred = torch.argmax(pred,dim=1)\n",
    "\n",
    "\n",
    "#print('prediction:', pred.shape)\n",
    "#print('labels:', labels.shape)\n",
    "\n",
    "print('output:',output.shape)\n",
    "print('labl', labels.shape)\n",
    "print('pred:',pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad8ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test plot_sample and plot_batch\n",
    "\n",
    "from train.metrics import plot_sample, plot_batch\n",
    "\n",
    "for idx,(images,labels) in enumerate(test_loader):\n",
    "#dataiter = iter(test_loader)\n",
    "#images, labels = dataiter.next()\n",
    "    with torch.no_grad():\n",
    "        output = model(images)\n",
    "        pred= torch.nn.functional.softmax(output,dim=1)\n",
    "        pred = torch.argmax(pred,dim=1)\n",
    "        plot_batch(pred,labels, images)\n",
    "        \n",
    "        for i in range(pred.shape[0]):\n",
    "            plot_sample(pred[i,:,:],labels[i,:,:], images[i,0:3,:,:]  )\n",
    "            break\n",
    "            #plot_pred_lbl_rgb(pred[i,:,:],labels[i,:,:], images[i,0:3,:,:]  )\n",
    "        if idx==0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to make sure tensorboard is working\n",
    "#!conda list | grep tensorboard\n",
    "import torch\n",
    "#!conda install tensorboard -y\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "print(torch.__version__)\n",
    "\n",
    "#make sure this executes\n",
    "SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f47c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise images in tensorboard\n",
    "from torchvision.utils import make_grid\n",
    "from datetime import datetime\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "# https://pytorch.org/vision/main/auto_examples/plot_visualization_utils.html#sphx-glr-auto-examples-plot-visualization-utils-py\n",
    "img_grid = make_grid(images)\n",
    "#show(img_grid)\n",
    "#matplotlib_imshow(img_grid, one_channel=False)\n",
    "#print('  '.join(classes[labels[j]] for j in range(4))\n",
    "# Default log_dir argument is \"runs\" - but it's good to be specific\n",
    "# torch.utils.tensorboard.SummaryWriter is imported above\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/visualise_data')\n",
    "\n",
    "# Write image data to TensorBoard log dir\n",
    "writer.add_image('Sat Images', img_grid)\n",
    "writer.flush()\n",
    "\n",
    "# To view, start TensorBoard on the command line with:\n",
    "#  tensorboard --logdir=runs\n",
    "# ...and open a browser tab to http://localhost:6006/\n",
    "\n",
    "#if on remote\n",
    "## on remote\n",
    "##tensorboard --logdir <path> --port 6006\n",
    "## forward everything on port 6006 on server to \n",
    "##ssh -L 16006:127.0.0.1:6006 -i vmexjobb_key.pem exjobbare@vdexjobb.westeurope.cloudapp.azure.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a5e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing model in tensorboard\n",
    "\n",
    "# Again, grab a single mini-batch of images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# add_graph() will trace the sample input through your model,\n",
    "# and render it as a graph.\n",
    "writer.add_graph(model, images)\n",
    "writer.flush()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a772cf3982d27f7efa5dd5ee7ce70eb2de69f36da9772dbcefc10fee67f331e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deepsat')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
