{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.utils import pNormalize, classCount\n",
    "from dataset.datasets import sentinel\n",
    "from dataset.stats import quantiles\n",
    "from model.models import UNET\n",
    "from torch.utils.data import DataLoader\n",
    "from train.utils import plots\n",
    "from train.metrics import computeConfMats, computeClassMetrics, wma, printClassMetrics, printModelMetrics, plotConfusionMatrices, plotConfusionMatrix\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams For Models\n",
    "BATCH_SIZE = 10\n",
    "NUM_WORKERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### MODEL 1 ############################### \n",
    "# <RGB Sentinel-2 TIMEPERIOD 1>\n",
    "\n",
    "q_hi = quantiles['high']['1'][0:3]           # NB! RGB!\n",
    "q_lo = quantiles['low']['1'][0:3]            # NB! RGB!\n",
    "norm = pNormalize(maxPer=q_hi, minPer=q_lo)\n",
    "\n",
    "# Create experimental dataset, rgb=True for 3 channels (default = False)\n",
    "# POINT TO FOLDER WITH TIMEPERIOD(S) WITH SUBFOLDERS: 'test, 'train, 'val\n",
    "test_set = sentinel(root_dir='./', img_transform=norm, data=\"test\", timeperiod=1, rgb=True) # NB! RGB!\n",
    "\n",
    "# Pass in the dataset into DataLoader to create an iterable over the dataset\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "# Define model\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "model_1 = UNET(in_channels=images.shape[1],classes=28)\n",
    "model_1.load_state_dict(torch.load('model_epoch_87.pt',map_location=torch.device('cpu'))) # Pass in 'trained_model.pt' and load model\n",
    "\n",
    "# 1 EPOCH TESTING\n",
    "dataiter = iter(test_loader) # Create an object which can be iterated one element at a time\n",
    "model_1.eval() # TOGGLE ON EVALUATION MODE\n",
    "with torch.no_grad():\n",
    "     cMats_1 = torch.zeros((27,2,2),dtype=torch.int32) # n_class - unclassified class, i.e. 28-1 = 27\n",
    "     \n",
    "     for images, labels in dataiter:\n",
    "          outputs = model_1(images)\n",
    "          preds = torch.nn.functional.softmax(outputs,dim=1)\n",
    "          preds = torch.argmax(preds,dim=1)\n",
    "          cMats_1 += computeConfMats(labels,preds)      \n",
    "\n",
    "#model_1.train() # TOGGLE ON TRAIN MODE WHEN EVALUATION IS DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Class IoU for Model 1\n",
    "iou_1 = computeClassMetrics(cMats_1)[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### MODEL 2 ###############################\n",
    "# <RGB Sentinel-2 TIMEPERIOD 2> \n",
    "\n",
    "q_hi = quantiles['high']['2'][0:3]           # NB! RGB!\n",
    "q_lo = quantiles['low']['2'][0:3]            # NB! RGB!\n",
    "norm = pNormalize(maxPer=q_hi, minPer=q_lo)\n",
    "\n",
    "# Create experimental dataset, rgb=True for 3 channels (default = False)\n",
    "# POINT TO FOLDER WITH TIMEPERIOD(S) WITH SUBFOLDERS: 'test, 'train, 'val\n",
    "test_set = sentinel(root_dir='./', img_transform=norm, data=\"test\", timeperiod=2, rgb=True) # NB! RGB!\n",
    "\n",
    "# Pass in the dataset into DataLoader to create an iterable over the dataset\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "# Define model\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "model_2 = UNET(in_channels=images.shape[1],classes=28)\n",
    "model_2.load_state_dict(torch.load('model_epoch_99.pt',map_location=torch.device('cpu'))) # Pass in 'trained_model.pt' and load model\n",
    "\n",
    "# 1 EPOCH TESTING\n",
    "dataiter = iter(test_loader) # Create an object which can be iterated one element at a time\n",
    "model_2.eval() # TOGGLE ON EVALUATION MODE\n",
    "with torch.no_grad():\n",
    "     cMats_2 = torch.zeros((27,2,2),dtype=torch.int32) # n_class - unclassified class, i.e. 28-1 = 27\n",
    "         \n",
    "     for images, labels in dataiter:\n",
    "          outputs = model_2(images)\n",
    "          preds = torch.nn.functional.softmax(outputs,dim=1)\n",
    "          preds = torch.argmax(preds,dim=1)\n",
    "          cMats_2 += computeConfMats(labels,preds)\n",
    "\n",
    "#model_2.train() # TOGGLE ON TRAIN MODE WHEN EVALUATION IS DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Class IoU for Model 2\n",
    "iou_2 = computeClassMetrics(cMats_2)[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Late Fusion Weights (Performance Weighting)\n",
    "iou_sum = iou_1 + iou_2\n",
    "\n",
    "for i in (range(len(iou_sum))):\n",
    "    if iou_sum[i] != 0:\n",
    "        iou_sum[i] = 1/iou_sum[i]\n",
    "\n",
    "lf_weights_1 = torch.multiply(iou_1, iou_sum)\n",
    "lf_weights_2 = torch.multiply(iou_2, iou_sum)\n",
    "\n",
    "# NB! Label 0 is uniformly-weighted (not performance weighted)\n",
    "s = torch.tensor([0.5])\n",
    "\n",
    "lf_weights_1 = torch.cat((s,lf_weights_1),dim=0)\n",
    "lf_weights_2 = torch.cat((s,lf_weights_2),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Late Fusion: Model 1 & Model 2 Using Performance Weighted Bayesian Sum Rule #################\n",
    "\n",
    "# Best way to iterate over 2 dataloaders (so memory leakage problem is avoided)\n",
    "# https://stackoverflow.com/questions/51444059/how-to-iterate-over-two-dataloaders-simultaneously-using-pytorch\n",
    "# Late Fusion as proposed by:\n",
    "# https://github.com/alessandrosebastianelli/S1-S2-DataFusion/blob/main/Main.ipynb\n",
    "\n",
    "q_hi_1 = quantiles['high']['1'][0:3]                   # NB! RGB!\n",
    "q_lo_1 = quantiles['low']['1'][0:3]                    # NB! RGB!\n",
    "norm_1 = pNormalize(maxPer=q_hi_1, minPer=q_lo_1)\n",
    "\n",
    "q_hi_2 = quantiles['high']['2'][0:3]                     # NB! RGB!\n",
    "q_lo_2 = quantiles['low']['2'][0:3]                      # NB! RGB!\n",
    "norm_2 = pNormalize(maxPer=q_hi_2, minPer=q_lo_2)\n",
    "\n",
    "# Create experimental dataset, rgb=True for 3 channels (default = False)\n",
    "# POINT TO FOLDER WITH TIMEPERIOD(S) WITH SUBFOLDERS: 'test, 'train, 'val\n",
    "test_set_1 = sentinel(root_dir='./', img_transform=norm_1, data=\"test\", timeperiod=1, rgb=True)  ### MODEL 1 <> NB! RGB!\n",
    "test_set_2 = sentinel(root_dir='./', img_transform=norm_2, data=\"test\", timeperiod=2, rgb=True)  ### MODEL 2 <> NB! RGB!\n",
    "\n",
    "# Pass in the dataset into DataLoader to create an iterable over the dataset\n",
    "test_loader_1 = DataLoader(test_set_1, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)                  ### MODEL 1\n",
    "test_loader_2 = DataLoader(test_set_2, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)                  ### MODEL 2\n",
    "\n",
    "# 1 EPOCH TESTING\n",
    "# Create an object which can be iterated one element at a time\n",
    "dataiter_1 = iter(test_loader_1) ### MODEL 1\n",
    "\n",
    "model_1.eval() # TOGGLE ON EVALUATION MODE\n",
    "model_2.eval() # TOGGLE ON EVALUATION MODE\n",
    "with torch.no_grad():         \n",
    "     cMats_lf = torch.zeros((27,2,2),dtype=torch.int32) # n_class - unclassified class, i.e. 28-1 = 27\n",
    "         \n",
    "     predarr = torch.tensor([],dtype=torch.int32)\n",
    "     labelarr = torch.tensor([],dtype=torch.int32)\n",
    "     \n",
    "     for i, (images_2, labels_2) in enumerate(test_loader_2):\n",
    "          \n",
    "          try:\n",
    "               (images_1, labels_1) = next(dataiter_1)\n",
    "          except StopIteration:\n",
    "               dataiter_1 = iter(test_loader_1)\n",
    "               (images_1, labels_1) = next(dataiter_1)\n",
    "               \n",
    "          outputs_1 = model_1(images_1)\n",
    "          outputs_2 = model_2(images_2)\n",
    "     \n",
    "          softmaxOutput_1 = torch.nn.functional.softmax(outputs_1,dim=1)\n",
    "          softmaxOutput_2 = torch.nn.functional.softmax(outputs_2,dim=1)\n",
    "     \n",
    "          for i in range(len(iou_sum)):\n",
    "               softmaxOutput_1[:,i,:,:] = torch.multiply(softmaxOutput_1[:,i,:,:],lf_weights_1[i])\n",
    "               softmaxOutput_2[:,i,:,:] = torch.multiply(softmaxOutput_2[:,i,:,:],lf_weights_2[i])\n",
    "     \n",
    "          softmaxWeightedSum = torch.add(softmaxOutput_1,softmaxOutput_2)\n",
    "     \n",
    "          preds = torch.argmax(softmaxWeightedSum,dim=1)\n",
    "          \n",
    "          cMats_lf += computeConfMats(labels_1,preds)                 ## NB! Labels for Model 1\n",
    "          \n",
    "          # Plot predictions\n",
    "          plots(preds, labels_1, images_1, savedir='./', idx=i, source='S2')\n",
    "          \n",
    "          # Flatten dimensions BxHxW --> B*H*W and concatenate\n",
    "          predarr = torch.cat((predarr, preds.reshape(-1)))\n",
    "          labelarr = torch.cat((labelarr, labels_1.reshape(-1)))      ## NB! Labels for Model 1\n",
    "          \n",
    "#model_1.train() # TOGGLE ON TRAIN MODE WHEN EVALUATION IS DONE\n",
    "#model_2.train()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Class Counts for Dataset 1\n",
    "classCounts,_ = classCount(test_loader_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Class and Model Metrics for Late Fusion Model\n",
    "class_metrics_lf = computeClassMetrics(cMats_lf)\n",
    "model_metrics_lf = wma(class_metrics_lf,classCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Model Metrics for Late Fusion Model\n",
    "printModelMetrics(model_metrics_lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Class Metrics for Late Fusion Model\n",
    "printClassMetrics(class_metrics_lf,classCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot N_CLASS X N_CLASS Confusion Matrix for Late Fusion Model\n",
    "plotConfusionMatrix(yTrue=labelarr,yPred=predarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Confusion Matrices for Late Fusion Model\n",
    "plotConfusionMatrices(cMats_lf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('exjobb_deepsat')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "116fc1d5d5babc57d8e6479c4c50e890e87180efd70e08af79116b08832f9fa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
