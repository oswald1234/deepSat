{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676f397-df6b-4a75-99bb-9efadd31b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################Calculate quantiles for dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from dataset.datasets import s2stats, senti\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "def my_quant(tens,hi=0.98,lo=0.02):\n",
    "    \n",
    "    def get_indices(q):\n",
    "        if int(q)<q:\n",
    "            ind = [int(q),int(q+1)]\n",
    "        else:\n",
    "            ind=[int(q)]\n",
    "        return(ind)\n",
    "    \n",
    "    def calc_quant(ind,sort):\n",
    "        if len(ind) >1:\n",
    "            q = (sort[ind[0]]+sort[ind[1]])/2    \n",
    "        else:\n",
    "            q=sort[ind]\n",
    "        return(q.numpy().item()) \n",
    "            \n",
    "    \n",
    "    sort,_ = torch.sort(tens)\n",
    "   \n",
    "    n = tens.shape[0]-1\n",
    "    ind_hi = get_indices(hi*(n))\n",
    "    ind_lo = get_indices(lo*(n))\n",
    "    return(calc_quant(ind_lo,sort),calc_quant(ind_hi,sort))\n",
    "\n",
    "#test=torch.rand(256*256*2638)\n",
    "#torchquant=torch.quantile(test,q=torch.tensor([0.02,0.98]),interpolation='midpoint')    \n",
    "\n",
    "dset= s2stats(root_dir='processed-data/dsen_2_256_split/timeperiod1/train/')\n",
    "\n",
    "quanthi=[]\n",
    "quantlo=[]\n",
    "for band in tqdm(range(10)):\n",
    "    for id,img in enumerate(tqdm(dset)):\n",
    "        if id==0:\n",
    "            conc=img[band,:,:].view(-1)\n",
    "        else:\n",
    "            conc=torch.cat((conc,img[band,:,:].view(-1)),0)\n",
    "        \n",
    "    q = my_quant(conc)\n",
    "    quanthi.append(q[0])\n",
    "    quantlo.append(q[1])\n",
    "    \n",
    "\n",
    "print(\"q_hi =\",quanthi)\n",
    "print('q_lo =',quantlo)\n",
    "#q_hi = [100.0, 158.0, 108.0, 75.0, 103.54399871826172, 76.29261779785156, 83.46126174926758, 68.2025260925293, 50.748931884765625, 37.05616760253906]\n",
    "#q_lo = [2102.0, 1714.0, 1398.0, 4716.0, 2433.3343505859375, 3686.039794921875, 4502.04052734375, 4839.02197265625, 3796.3406982421875, 2994.882568359375]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d086b04-69b6-4e55-be7d-71df606d474a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### calculate std and mean for dataset\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.datasets import s2stats\n",
    "import torch\n",
    "import numpy as np\n",
    "dset= s2stats(root_dir='processed-data/dsen_2_256_split/timeperiod1/train/')\n",
    "\n",
    "loader = DataLoader(dset,\n",
    "                         batch_size=1,\n",
    "                         num_workers=0,\n",
    "                         shuffle=False)\n",
    "\n",
    "loader = tqdm(loader)\n",
    "mean = 0.\n",
    "var = 0.\n",
    "ninstance=0.\n",
    "for images in loader:\n",
    "    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    \n",
    "    m=images.mean(2).sum(0)\n",
    "    v=images.var(2).sum(0)\n",
    "    \n",
    "    if not torch.any(torch.isinf(v)):\n",
    "        mean += m\n",
    "        var += v\n",
    "        ninstance += batch_samples\n",
    "\n",
    "mean /= ninstance\n",
    "var /= ninstance\n",
    "std = torch.sqrt(var)\n",
    "\n",
    "print('std = ',std.numpy())\n",
    "print('mean =',mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbcbc833-9265-4b8b-a09b-2ec50f7e64a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_hi = [100.0, 158.0, 108.0, 75.0, 103.54399871826172, 76.29261779785156, 83.46126174926758, 68.2025260925293, 50.748931884765625, 37.05616760253906]\n",
      "q_lo = [2102.0, 1714.0, 1398.0, 4716.0, 2433.3343505859375, 3686.039794921875, 4502.04052734375, 4839.02197265625, 3796.3406982421875, 2994.882568359375]\n"
     ]
    }
   ],
   "source": [
    "##some functions\n",
    "import torch\n",
    "\n",
    "#------------quant_batch----------------------\n",
    "# takes in tensor of shape [batchsize,band,H,w]\n",
    "# max batchsize is 256\n",
    "# permutes dimensions to [band,batchsize,H,W]\n",
    "# flattens dimensions to [band,batchsize*H*W]\n",
    "# calculates quantile for each band on dim=1\n",
    "\n",
    "def quant_batch(imbatch,q=torch.tensor([0.02,0.98])):\n",
    "    perm = imbatch.permute(1,0,2,3).flatten(start_dim=1)\n",
    "    q = torch.quantile(perm, q, dim=1,interpolation='midpoint')\n",
    "    return(q)\n",
    "\n",
    "#------example use case\n",
    "# define dataset and dataloader, \n",
    "# dset= s2stats(root_dir='processed-data/dsen_2_256_split/*/*/')\n",
    "# dloader = DataLoader(dset, batch_size=(100), num_workers=0,pin_memory=True,shuffle=True)\n",
    "#\n",
    "# dataiter = iter(dloader)\n",
    "# imgs = dataiter.next()\n",
    "#  \n",
    "# qbatch = quant_batch(imgs.float())\n",
    "# qbatch.shape\n",
    "# output: torch.Size([2,10]) eg  index [0,1] = lower quantile for band 1\n",
    "\n",
    "\n",
    "#----------mean_batch--------\n",
    "# takes in tensor of shape [batchsize,band,H,w]\n",
    "# replaces all inf values with nan to prevent overflow\n",
    "# calculates mean for each band\n",
    "# returns mean for each band: torch.Size[channels]\n",
    "def mean_batch(batch):\n",
    "    b=batch.nan_to_num(nan=torch.nan, posinf=torch.nan, neginf=torch.nan)\n",
    "    return(torch.nanmean(batch,dim=(0,2,3),out=torch.empty(batch.shape[1])))\n",
    "#-----------std_batch----------\n",
    "# takes in tensor of shape [batchsize,band,H,w]\n",
    "# replaces all inf values with nan to prevent overflow\n",
    "# convert to numpy array\n",
    "# calculates std for each band\n",
    "# returns std for each band: torch.Size[channels]\n",
    "def std_batch(batch):\n",
    "    b=batch.nan_to_num(nan=torch.nan,posinf=torch.nan,neginf=torch.nan).numpy()\n",
    "    std =np.nanstd(b,axis=(0,2,3),out=np.empty(batch.shape[1]))\n",
    "    return(torch.from_numpy(std))\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepsat]",
   "language": "python",
   "name": "conda-env-deepsat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
