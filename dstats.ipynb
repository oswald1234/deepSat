{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c5c63b82-d7aa-4568-9342-95b502cbc261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba53b0fa2ed42abb60e90ed94e93fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee8c1fbf5c04c388ba9484bc81665b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ad8151fcd64f0eb44454b36f230b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80a24bd0bc94e3293438e7f337d4bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff94d03094846ed97b87415d1397d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee6f3a2047d4f43bbf11242dedc60ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40d335f4f234b1da6c9ae8ca5fccb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e921a8c668b44a0bfb3e4b232dc11af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5fc8be71f842288daf9eb583c9ff54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2384f7d4543c497eacae17d524212dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d40a06b7427437cbb6b49d89aa38739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_hi = [2102.0, 1716.0, 1398.0, 4732.0, 2434.42919921875, 3701.759765625, 4519.2177734375, 4857.7734375, 3799.80322265625, 3008.8935546875]\n",
      "q_lo = [102.0, 159.0, 107.0, 77.0, 106.98081970214844, 79.00384521484375, 86.18966674804688, 70.40167236328125, 50.571197509765625, 36.95356750488281]\n",
      "median = [368.0, 514.0, 301.0, 2614.0, 870.4588623046875, 2146.507568359375, 2500.57275390625, 2722.222412109375, 1718.282958984375, 900.8515625]\n"
     ]
    }
   ],
   "source": [
    "#### Calculate quantiles for dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from dataset.datasets import s2stats, sentinel\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "def my_quant(tens,hi=0.98,lo=0.02):\n",
    "    \n",
    "    def get_indices(q):\n",
    "        if int(q)<q:\n",
    "            ind = [int(q),int(q+1)]\n",
    "        else:\n",
    "            ind=[int(q)]\n",
    "        return(ind)\n",
    "    \n",
    "    def calc_quant(ind,sort):\n",
    "        if len(ind) >1:\n",
    "            q = (sort[ind[0]]+sort[ind[1]])/2    \n",
    "        else:\n",
    "            q=sort[ind]\n",
    "        return(q.numpy().item()) \n",
    "            \n",
    "    \n",
    "    sort,_ = torch.sort(tens)\n",
    "   \n",
    "    n = tens.shape[0]-1\n",
    "    ind_hi = get_indices(hi*(n))\n",
    "    ind_lo = get_indices(lo*(n))\n",
    "    return(calc_quant(ind_lo,sort),calc_quant(ind_hi,sort))\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "quanthi=[]\n",
    "quantlo=[]\n",
    "median_bands=[]\n",
    "dset= s2stats(root_dir='processed-data/dsen_2_256_new_split/timeperiod1/train/')\n",
    "\n",
    "for band in tqdm(range(10)):\n",
    "    for id,(img,_) in enumerate(tqdm(dset)):\n",
    "        if id==0:\n",
    "            conc=img[band,:,:].view(-1)\n",
    "        else:\n",
    "            conc=torch.cat((conc,img[band,:,:].view(-1)),0)\n",
    "        \n",
    "    q = my_quant(conc)\n",
    "    quantlo.append(q[0])\n",
    "    quanthi.append(q[1])\n",
    "    median_bands.append(conc.median().item())\n",
    "\n",
    "print(\"q_hi =\",quanthi)\n",
    "print('q_lo =',quantlo)\n",
    "print('median =', median_bands)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef964cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classCounts (count how many pixels of each class).\n",
    "\n",
    "from dataset.utils import classCount,pNormalize\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from dataset.datasets import sentinel\n",
    "# Create experimental dataset, rgb=True for 3 channels (default = False)\n",
    "# POINT TO FOLDER WITH TIMEPERIOD(S) WITH SUBFOLDERS: 'test, 'train, 'val\n",
    "q_hi = torch.tensor([2102.0, 1716.0, 1398.0, 4732.0, 2434.42919921875, 3701.759765625, 4519.2177734375, 4857.7734375, 3799.80322265625, 3008.8935546875])\n",
    "q_lo = torch.tensor([102.0, 159.0, 107.0, 77.0, 106.98081970214844, 79.00384521484375, 86.18966674804688, 70.40167236328125, 50.571197509765625, 36.95356750488281])    \n",
    "norm = pNormalize(maxPer=q_hi,minPer=q_lo)\n",
    "\n",
    "def get_set_classcounts(timeperiod=1):\n",
    "    BATCH_SIZE=10\n",
    "    NUM_WORKERS = 2 \n",
    "    test_set = sentinel(root_dir='processed-data/dsen_2_256_new_split/', img_transform=norm,data=\"test\",timeperiod=timeperiod)\n",
    "    train_set=sentinel(root_dir='processed-data/dsen_2_256_new_split/', img_transform=norm,data=\"train\",timeperiod=timeperiod)\n",
    "    val_set=sentinel(root_dir='processed-data/dsen_2_256_new_split/', img_transform=norm,data=\"val\",timeperiod=timeperiod)\n",
    "    \n",
    "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "    val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "    test_classCounts,_ = classCount(test_loader)\n",
    "    train_classCounts,_ = classCount(train_loader)\n",
    "    val_classCounts,_ = classCount(val_loader)\n",
    "    \n",
    "    return(test_classCounts,train_classCounts,val_classCounts)\n",
    "\n",
    "test_cc1,train_cc1,val_cc1 = get_set_classcounts(timeperiod=1)\n",
    "test_cc2,train_cc2,val_cc2 = get_set_classcounts(timeperiod=2)\n",
    "\n",
    "classCounts= {\n",
    "    'test':{\n",
    "        '1':test_cc1,\n",
    "        '2':test_cc2},\n",
    "    'train':{\n",
    "        '1':train_cc1,\n",
    "        '2':train_cc2},\n",
    "    'val':{\n",
    "        '1':val_cc1,\n",
    "        '2':val_cc2}\n",
    "}\n",
    "\n",
    "classCounts1= {\n",
    "    'test':test_cc1,\n",
    "    'train':train_cc1,\n",
    "    'val':val_cc1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d086b04-69b6-4e55-be7d-71df606d474a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9c2825dbd94d01b67d092c5e74973a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2666 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std =  [430.30618 318.0648  278.14877 913.9487  457.92636 703.9294  868.6249\n",
      " 938.2669  712.49786 574.31647]\n",
      "mean = [ 586.7766   631.345    428.83728 2637.2136  1001.9254  2125.3447\n",
      " 2516.8843  2738.1897  1790.8623  1083.3242 ]\n"
     ]
    }
   ],
   "source": [
    "#### calculate std and mean for dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.datasets import s2stats\n",
    "import torch\n",
    "import numpy as np\n",
    "dset= s2stats(root_dir='processed-data/dsen_2_256_new_split/timeperiod1/train/')\n",
    "\n",
    "loader = DataLoader(dset,\n",
    "                         batch_size=1,\n",
    "                         num_workers=0,\n",
    "                         shuffle=False)\n",
    "\n",
    "loader = tqdm(loader)\n",
    "mean = 0.\n",
    "var = 0.\n",
    "ninstance=0.\n",
    "for images in loader:\n",
    "    batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    \n",
    "    m=images.mean(2).sum(0)\n",
    "    v=images.var(2).sum(0)\n",
    "   \n",
    "    if not torch.any(torch.isinf(v)):\n",
    "        mean += m\n",
    "        var += v\n",
    "        ninstance += batch_samples\n",
    "\n",
    "mean /= ninstance\n",
    "var /= ninstance\n",
    "std = torch.sqrt(var)\n",
    "\n",
    "print('std = ',std.numpy())\n",
    "print('mean =',mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cbcbc833-9265-4b8b-a09b-2ec50f7e64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  some functions\n",
    "import torch\n",
    "\n",
    "#------------quant_batch----------------------\n",
    "# takes in tensor of shape [batchsize,band,H,w]\n",
    "# max batchsize is 256\n",
    "# permutes dimensions to [band,batchsize,H,W]\n",
    "# flattens dimensions to [band,batchsize*H*W]\n",
    "# calculates quantile for each band on dim=1\n",
    "\n",
    "def quant_batch(imbatch,q=torch.tensor([0.02,0.98])):\n",
    "    perm = imbatch.permute(1,0,2,3).flatten(start_dim=1)\n",
    "    q = torch.quantile(perm, q, dim=1,interpolation='midpoint')\n",
    "    return(q)\n",
    "\n",
    "#------example use case\n",
    "# define dataset and dataloader, \n",
    "# dset= s2stats(root_dir='processed-data/dsen_2_256_split/*/*/')\n",
    "# dloader = DataLoader(dset, batch_size=(100), num_workers=0,pin_memory=True,shuffle=True)\n",
    "#\n",
    "# dataiter = iter(dloader)\n",
    "# imgs = dataiter.next()\n",
    "#  \n",
    "# qbatch = quant_batch(imgs.float())\n",
    "# qbatch.shape\n",
    "# output: torch.Size([2,10]) eg  index [0,1] = lower quantile for band 1\n",
    "\n",
    "\n",
    "#----------mean_batch--------\n",
    "# takes in tensor of shape [batchsize,band,H,w]\n",
    "# replaces all inf values with nan to prevent overflow\n",
    "# calculates mean for each band\n",
    "# returns mean for each band: torch.Size[channels]\n",
    "def mean_batch(batch):\n",
    "    b=batch.nan_to_num(nan=torch.nan, posinf=torch.nan, neginf=torch.nan)\n",
    "    return(torch.nanmean(batch,dim=(0,2,3),out=torch.empty(batch.shape[1])))\n",
    "#-----------std_batch----------\n",
    "# takes in tensor of shape [batchsize,band,H,w]\n",
    "# replaces all inf values with nan to prevent overflow\n",
    "# convert to numpy array\n",
    "# calculates std for each band\n",
    "# returns std for each band: torch.Size[channels]\n",
    "def std_batch(batch):\n",
    "    b=batch.nan_to_num(nan=torch.nan,posinf=torch.nan,neginf=torch.nan).numpy()\n",
    "    std =np.nanstd(b,axis=(0,2,3),out=np.empty(batch.shape[1]))\n",
    "    return(torch.from_numpy(std))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4307aa03-52ae-4ead-a809-d9a10ca2dcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16779497073542ccb66d99ca28f8795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf img from sentinel:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "#### check inf values\n",
    "\n",
    "import torch\n",
    "from dataset.datasets import s2stats, sentinel\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#stat= s2stats(root_dir='processed-data/dsen_2_256_new_split/timeperiod1/train/')\n",
    "sent= sentinel(root_dir='processed-data/dsen_2_256_new_split/timeperiod1/train/')\n",
    "\n",
    "def isinf(img):\n",
    "    return(torch.any(torch.isinf(img)))\n",
    "\n",
    "statinf=[]\n",
    "sentinf=[]\n",
    "for ind,(img,_) in enumerate(tqdm(sent)):\n",
    "    if isinf(img):\n",
    "        sentinf.append(ind)\n",
    "        \n",
    "       \n",
    "print('inf img from sentinel:\\n',len(sentinf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepsat]",
   "language": "python",
   "name": "conda-env-deepsat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
